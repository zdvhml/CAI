import requests
import os
import re

def download_images(base_url):
    """
    æ ¹æ®åŸºç¡€ç½‘å€è‡ªåŠ¨ä¸‹è½½å…­å¼ å›¾ç‰‡å¹¶é‡å‘½å
    æ”¯æŒä»»æ„æ•°å­—å‰ç¼€ï¼š0_u.jpg / 1_u.jpg / 2_u.jpg ...
    ä¿å­˜ç›®å½•è‡ªåŠ¨è·Ÿéšå‰ç¼€ï¼šimages0 / images1 / images2 ...
    ç¤ºä¾‹è¾“å…¥ï¼šwww.xxx.com/222/333/1_u.jpgï¼ˆä»»æ„ä¸€å¼ å›¾ç‰‡çš„ç½‘å€ï¼‰
    """

    # ç¡®ä¿ç½‘å€åŒ…å«åè®®å¤´
    if not base_url.startswith("http"):
        base_url = "https://" + base_url

    # æå–ç›®å½•è·¯å¾„å’Œæ–‡ä»¶å
    base_dir, filename = base_url.rsplit("/", 1)

    # è‡ªåŠ¨è¯†åˆ«æ–‡ä»¶åä¸­çš„æ•°å­—å‰ç¼€ï¼Œä¾‹å¦‚ 0_u.jpg â†’ 0ï¼Œ1_u.jpg â†’ 1ï¼Œ2_u.jpg â†’ 2
    match = re.match(r"^(\d+)_[a-z]+\.jpg$", filename, re.IGNORECASE)
    if not match:
        print("âŒ æ— æ³•è¯†åˆ«æ–‡ä»¶åæ ¼å¼ï¼Œè¯·ç¡®ä¿æ ¼å¼ä¸ºï¼šæ•°å­—_å­—æ¯.jpgï¼ˆå¦‚ 0_u.jpgã€1_u.jpgï¼‰")
        return

    prefix = match.group(1)
    print(f"ğŸ” æ£€æµ‹åˆ°æ–‡ä»¶å‰ç¼€ï¼š{prefix}_\n")

    # å®šä¹‰åç¼€ -> æ–°æ–‡ä»¶åæ˜ å°„ï¼ˆå‰ç¼€è‡ªåŠ¨è·Ÿéšè¾“å…¥ç½‘å€å˜åŒ–ï¼‰
    file_map = {
        f"{prefix}_u.jpg": "uu.jpg",
        f"{prefix}_l.jpg": "ll.jpg",
        f"{prefix}_r.jpg": "rr.jpg",
        f"{prefix}_d.jpg": "dd.jpg",
        f"{prefix}_b.jpg": "bb.jpg",
        f"{prefix}_a.jpg": "aa.jpg",
    }

    # ä¿å­˜ç›®å½•è‡ªåŠ¨è·Ÿéšå‰ç¼€ï¼šimages0 / images1 / images2 ...
    save_dir = f"images{prefix}"
    os.makedirs(save_dir, exist_ok=True)

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                      "AppleWebKit/537.36 (KHTML, like Gecko) "
                      "Chrome/120.0.0.0 Safari/537.36"
    }

    print(f"ğŸ“‚ ä¿å­˜ç›®å½•ï¼š{os.path.abspath(save_dir)}\n")

    for original_name, new_name in file_map.items():
        url = f"{base_dir}/{original_name}"
        save_path = os.path.join(save_dir, new_name)

        try:
            print(f"â¬‡ï¸  æ­£åœ¨ä¸‹è½½ï¼š{url}")
            response = requests.get(url, headers=headers, timeout=15)
            response.raise_for_status()

            with open(save_path, "wb") as f:
                f.write(response.content)

            size_kb = len(response.content) / 1024
            print(f"   âœ… å·²ä¿å­˜ä¸ºï¼š{save_dir}/{new_name}ï¼ˆ{size_kb:.1f} KBï¼‰\n")

        except requests.exceptions.HTTPError as e:
            print(f"   âŒ HTTP é”™è¯¯ï¼š{e}\n")
        except requests.exceptions.ConnectionError:
            print(f"   âŒ è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘å€æ˜¯å¦æ­£ç¡®\n")
        except requests.exceptions.Timeout:
            print(f"   âŒ è¯·æ±‚è¶…æ—¶\n")
        except Exception as e:
            print(f"   âŒ æœªçŸ¥é”™è¯¯ï¼š{e}\n")

    print(f"ğŸ‰ ä¸‹è½½ä»»åŠ¡å®Œæˆï¼æ–‡ä»¶å·²ä¿å­˜è‡³ {save_dir}/")


if __name__ == "__main__":
    # âœï¸ ç²˜è´´ä»»æ„ä¸€å¼ å›¾ç‰‡çš„ç½‘å€ï¼Œè„šæœ¬è‡ªåŠ¨è¯†åˆ«å‰ç¼€ã€ç›®å½•å’Œæ–‡ä»¶å
    user_url = input("è¯·è¾“å…¥ä»»æ„ä¸€å¼ å›¾ç‰‡çš„ç½‘å€ï¼ˆä¾‹å¦‚ï¼šwww.xxx.com/222/333/2_u.jpgï¼‰ï¼š\n> ").strip()
    download_images(user_url)
